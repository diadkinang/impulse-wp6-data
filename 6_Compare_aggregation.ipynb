{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92fe7e54",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In this notebook, I compare several aggregation strategies for combining replicate-level morphological profiles into compound-level features. Cell Painting experiments often include multiple replicates per compound, and the method of aggregation can significantly affect downstream model performance.\n",
    "\n",
    "The main goal is to evaluate how different aggregation techniques influence the accuracy and generalization ability of MoA classification models.\n",
    "\n",
    "Specifically, I assess the following strategies:\n",
    "- Arithmetic mean\n",
    "- Geometric mean\n",
    "- Arithmetic–geometric mean (AGM)\n",
    "- Selection of the closest replicate to each mean-based reference\n",
    "\n",
    "Each approach is applied to the same underlying data, and the resulting models are compared using accuracy and macro F1-score. The objective is to identify the most effective and reliable method for morphological profile summarization in multimodal pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae25dc58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from datetime import date\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85165c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths to data\n",
    "save_path = \"result/\"\n",
    "\n",
    "def load_latest_file(suffix: str):\n",
    "    # loading dataset\n",
    "    file_merged_type = '/*[0-9]_' + suffix\n",
    "    files_merged = glob.glob(save_path + file_merged_type)\n",
    "\n",
    "    # gets latest file\n",
    "    max_file_merged = max(files_merged, key=os.path.getctime)\n",
    "\n",
    "    # load file\n",
    "    return pd.read_csv(max_file_merged)\n",
    "\n",
    "# load file\n",
    "df_merged_exp_mean = load_latest_file('merged_exp_mean.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c493ba1d",
   "metadata": {},
   "source": [
    "We need to prepare nessary variables for our pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5bb65777",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_cols = [col for col in df_merged_exp_mean.columns if col.startswith('Metadata_')]\n",
    "binary_cols = [col for col in df_merged_exp_mean.columns if col.startswith('binary_')]\n",
    "chemical_cols = [col for col in df_merged_exp_mean.columns if col.startswith('chemical_')]\n",
    "moa_cols = [col for col in df_merged_exp_mean.columns if col.startswith('moa_')]\n",
    "drug_status_cols = [col for col in df_merged_exp_mean.columns if col.startswith('drug_status_')]\n",
    "fingerprints_cols = [col for col in df_merged_exp_mean.columns if col.startswith('fp_')]\n",
    "morphology_cols = [col for col in df_merged_exp_mean.columns if col.startswith('morphology_')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b1ee1c4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['moa_inhibitor', 'moa_antagonist', 'moa_agonist']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moa_counts = df_merged_exp_mean[moa_cols].sum().sort_values(ascending=False)\n",
    "top_moa = moa_counts[moa_counts > 100].index.tolist()\n",
    "top_moa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e0ebc9",
   "metadata": {},
   "source": [
    "We will use our previous pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8566b990",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score, roc_curve, auc, roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "class MultimodalMoAPipeline:\n",
    "    \"\"\"\n",
    "    A pipeline for multimodal classification tasks using morphological, chemical,\n",
    "    and fingerprint features.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    morph_cols : list of str, default=[]\n",
    "        List of column names representing morphological features.\n",
    "\n",
    "    chem_cols : list of str, default=[]\n",
    "        List of column names representing chemical descriptors.\n",
    "\n",
    "    fp_cols : list of str, default=[]\n",
    "        List of column names representing fingerprint features.\n",
    "\n",
    "    use_morph : bool, default=True\n",
    "        Whether to include morphological features in the model.\n",
    "\n",
    "    use_chem : bool, default=True\n",
    "        Whether to include chemical features in the model.\n",
    "\n",
    "    use_fp : bool, default=True\n",
    "        Whether to include fingerprint features in the model.\n",
    "\n",
    "    scaler : str or None, default='standard'\n",
    "        Type of scaler to apply to features. Options:\n",
    "            - 'standard': StandardScaler from sklearn\n",
    "            - None or any other value: no scaling will be applied\n",
    "\n",
    "        Note: Some models like CatBoost do not require scaling.\n",
    "\n",
    "    model : sklearn-like classifier, default=None\n",
    "        A scikit-learn compatible classifier. If None, defaults to\n",
    "        RandomForestClassifier with predefined parameters.\n",
    "\n",
    "    random_state : int, default=42\n",
    "        Random seed for reproducibility.\n",
    "\n",
    "    use_gridsearch : bool, default=False\n",
    "        Whether to perform GridSearchCV to tune hyperparameters.\n",
    "        Only supported for sklearn-compatible estimators.\n",
    "    \"\"\"\n",
    "    def __init__(self, morph_cols=[], chem_cols=[], fp_cols=[],\n",
    "                 use_morph=True, use_chem=True, use_fp=True,\n",
    "                 scaler='standard', model=None, random_state=42,\n",
    "                 use_gridsearch=False):\n",
    "        self.morph_cols = morph_cols\n",
    "        self.chem_cols = chem_cols\n",
    "        self.fp_cols = fp_cols\n",
    "        self.use_morph = use_morph\n",
    "        self.use_chem = use_chem\n",
    "        self.use_fp = use_fp\n",
    "        \n",
    "        self.scaler_type = scaler\n",
    "        self.random_state = random_state\n",
    "        self.use_gridsearch = use_gridsearch\n",
    "        \n",
    "        self.model = model if model is not None else RandomForestClassifier(n_estimators=200, random_state=random_state, class_weight='balanced', min_samples_leaf=3)\n",
    "\n",
    "    def _get_feature_set(self, df):\n",
    "        cols = []\n",
    "        if self.use_morph:\n",
    "            cols += self.morph_cols\n",
    "        if self.use_chem:\n",
    "            cols += self.chem_cols\n",
    "        if self.use_fp:\n",
    "            cols += self.fp_cols\n",
    "        return df[cols].copy()\n",
    "\n",
    "    def _scale(self, X):\n",
    "        if self.scaler_type == 'standard':\n",
    "            self.scaler = StandardScaler()\n",
    "            X_scaled = pd.DataFrame(self.scaler.fit_transform(X), columns=X.columns, index=X.index)\n",
    "            return X_scaled\n",
    "        return X  # no scaling\n",
    "\n",
    "    def fit(self, df, target_col):\n",
    "        X = self._get_feature_set(df)\n",
    "        X = self._scale(X)\n",
    "\n",
    "        # Support for multilabel: if target_col — it's a one-hot list\n",
    "        if isinstance(target_col, list):\n",
    "            df = df.copy()\n",
    "            df['__moa_label'] = df[target_col].idxmax(axis=1)\n",
    "            y = df['__moa_label']\n",
    "        else:\n",
    "            y = df[target_col]\n",
    "\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(\n",
    "            X, y, stratify=y, test_size=0.2, random_state=self.random_state\n",
    "        )\n",
    "\n",
    "        if self.use_gridsearch:\n",
    "            param_grid = {\n",
    "                'n_estimators': [100, 200],\n",
    "                'max_depth': [None, 10, 20],\n",
    "                'min_samples_leaf': [1, 3, 5],\n",
    "                'class_weight': ['balanced']\n",
    "            }\n",
    "            base_model = RandomForestClassifier(random_state=self.random_state)\n",
    "            cv_strategy = StratifiedKFold(n_splits=3, shuffle=True, random_state=self.random_state)\n",
    "            grid = GridSearchCV(base_model, param_grid, scoring='f1_macro', cv=cv_strategy, n_jobs=-1)\n",
    "            grid.fit(self.X_train, self.y_train)\n",
    "            print(\"Best params from GridSearchCV:\", grid.best_params_)\n",
    "            self.model = grid.best_estimator_\n",
    "        else:\n",
    "            self.model.fit(self.X_train, self.y_train)\n",
    "\n",
    "        self.y_pred = self.model.predict(self.X_test)\n",
    "\n",
    "\n",
    "    def evaluate(self, show_plots=True):\n",
    "        acc = accuracy_score(self.y_test, self.y_pred)\n",
    "        f1 = f1_score(self.y_test, self.y_pred, average='macro')\n",
    "\n",
    "        print(f\"\\n🎯 Accuracy: {acc:.4f}\")\n",
    "        print(f\"🎯 Macro F1-score: {f1:.4f}\\n\")\n",
    "        print(\"Classification Report:\\n\")\n",
    "        print(classification_report(self.y_test, self.y_pred))\n",
    "        \n",
    "        if not show_plots:\n",
    "            return\n",
    "\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        cm = confusion_matrix(self.y_test, self.y_pred, labels=self.model.classes_)\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                    xticklabels=self.model.classes_, yticklabels=self.model.classes_)\n",
    "        plt.title(\"Confusion Matrix\")\n",
    "        plt.xlabel(\"Predicted\")\n",
    "        plt.ylabel(\"True\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # PR and ROC curves only for binary classification\n",
    "        if len(self.model.classes_) == 2:\n",
    "            y_proba = self.model.predict_proba(self.X_test)[:, 1]\n",
    "\n",
    "            # Precision-Recall Curve\n",
    "            precision, recall, thresholds = precision_recall_curve(self.y_test, y_proba)\n",
    "            avg_precision = average_precision_score(self.y_test, y_proba)\n",
    "\n",
    "            plt.figure(figsize=(8, 6))\n",
    "            plt.plot(recall, precision, marker='.')\n",
    "            plt.xlabel('Recall')\n",
    "            plt.ylabel('Precision')\n",
    "            plt.title(f'Precision-Recall Curve (AP = {avg_precision:.4f})')\n",
    "            plt.grid()\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "            # ROC Curve\n",
    "            fpr, tpr, _ = roc_curve(self.y_test, y_proba)\n",
    "            roc_auc = roc_auc_score(self.y_test, y_proba)\n",
    "\n",
    "            plt.figure(figsize=(8, 6))\n",
    "            plt.plot(fpr, tpr, label=f'ROC curve (AUC = {roc_auc:.4f})')\n",
    "            plt.plot([0, 1], [0, 1], linestyle='--', color='gray')\n",
    "            plt.xlabel('False Positive Rate')\n",
    "            plt.ylabel('True Positive Rate')\n",
    "            plt.title('ROC Curve')\n",
    "            plt.legend(loc='lower right')\n",
    "            plt.grid()\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "    def plot_importance(self, top_n=30):\n",
    "        if not hasattr(self.model, 'feature_importances_'):\n",
    "            print(\"This model does not support feature importances.\")\n",
    "            return\n",
    "\n",
    "        feat_imp = pd.DataFrame({\n",
    "            'feature': self.X_train.columns,\n",
    "            'importance': self.model.feature_importances_\n",
    "        })\n",
    "\n",
    "        # Figure out the feature groups\n",
    "        def get_group(feature):\n",
    "            if feature in self.morph_cols:\n",
    "                return 'morphology'\n",
    "            elif feature in self.chem_cols:\n",
    "                return 'chemistry'\n",
    "            elif feature in self.fp_cols:\n",
    "                return 'fingerprint'\n",
    "            else:\n",
    "                return 'other'\n",
    "\n",
    "        feat_imp['group'] = feat_imp['feature'].apply(get_group)\n",
    "\n",
    "        # Group by feature group and sum importances\n",
    "        grouped = feat_imp.groupby('group')['importance'].sum().sort_values(ascending=False)\n",
    "        print(\"\\n📊 Feature Importance by Group:\")\n",
    "        print(grouped)\n",
    "\n",
    "        # Sort and select top_n features\n",
    "        feat_imp = feat_imp.sort_values(by='importance', ascending=False).head(top_n)\n",
    "\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        sns.barplot(data=feat_imp, x='importance', y='feature', hue='group', dodge=False, palette='viridis')\n",
    "        plt.title(f\"Top {top_n} Feature Importances by Group\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        return feat_imp\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb76dccf",
   "metadata": {},
   "source": [
    "Our baseline model is based on CatBoost Classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9fe8b207",
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "X = df_merged_exp_mean[morphology_cols + chemical_cols + fingerprints_cols]\n",
    "y = df_merged_exp_mean[top_moa].idxmax(axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
    "\n",
    "classes = y_train.unique()\n",
    "weights = compute_class_weight(class_weight='balanced', classes=classes, y=y_train)\n",
    "class_weights = dict(zip(classes, weights))\n",
    "\n",
    "cat_boost_model = CatBoostClassifier(\n",
    "    iterations=300,\n",
    "    depth=6,\n",
    "    learning_rate=0.1,\n",
    "    loss_function='MultiClass',\n",
    "    class_weights=class_weights,\n",
    "    eval_metric='TotalF1',\n",
    "    random_seed=42,\n",
    "    verbose=50,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "071b5d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_boost_pipe = MultimodalMoAPipeline(\n",
    "    morph_cols=morphology_cols,\n",
    "    chem_cols=chemical_cols,\n",
    "    fp_cols=fingerprints_cols,\n",
    "    use_gridsearch=False,\n",
    "    model=cat_boost_model\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e841d7bf",
   "metadata": {},
   "source": [
    "Now we will test our pipeline on mean-based aggregation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8bc00cd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.5930239\ttotal: 64.2ms\tremaining: 19.2s\n",
      "50:\tlearn: 0.9769683\ttotal: 1.75s\tremaining: 8.55s\n",
      "100:\tlearn: 0.9940559\ttotal: 3.37s\tremaining: 6.63s\n",
      "150:\tlearn: 1.0000000\ttotal: 4.83s\tremaining: 4.77s\n",
      "200:\tlearn: 1.0000000\ttotal: 6.26s\tremaining: 3.08s\n",
      "250:\tlearn: 1.0000000\ttotal: 7.67s\tremaining: 1.5s\n",
      "299:\tlearn: 1.0000000\ttotal: 9.05s\tremaining: 0us\n",
      "\n",
      "🎯 Accuracy: 0.8795\n",
      "🎯 Macro F1-score: 0.3535\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "   moa_agonist       0.50      0.07      0.12        14\n",
      "moa_antagonist       0.00      0.00      0.00        12\n",
      " moa_inhibitor       0.89      0.99      0.94       198\n",
      "\n",
      "      accuracy                           0.88       224\n",
      "     macro avg       0.46      0.35      0.35       224\n",
      "  weighted avg       0.82      0.88      0.83       224\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cat_boost_pipe.fit(df_merged_exp_mean, target_col=top_moa)\n",
    "cat_boost_pipe.evaluate(show_plots=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c16d042",
   "metadata": {},
   "source": [
    "Now we will test our pipeline on geometric mean aggregation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90630ea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.5081643\ttotal: 47.7ms\tremaining: 14.3s\n",
      "50:\tlearn: 0.9704265\ttotal: 1.43s\tremaining: 6.98s\n",
      "100:\tlearn: 0.9953284\ttotal: 3.08s\tremaining: 6.08s\n",
      "150:\tlearn: 0.9995759\ttotal: 4.65s\tremaining: 4.59s\n",
      "200:\tlearn: 1.0000000\ttotal: 6.08s\tremaining: 2.99s\n",
      "250:\tlearn: 1.0000000\ttotal: 7.52s\tremaining: 1.47s\n",
      "299:\tlearn: 1.0000000\ttotal: 8.9s\tremaining: 0us\n",
      "\n",
      "🎯 Accuracy: 0.8616\n",
      "🎯 Macro F1-score: 0.3086\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "   moa_agonist       0.00      0.00      0.00        14\n",
      "moa_antagonist       0.00      0.00      0.00        12\n",
      " moa_inhibitor       0.88      0.97      0.93       198\n",
      "\n",
      "      accuracy                           0.86       224\n",
      "     macro avg       0.29      0.32      0.31       224\n",
      "  weighted avg       0.78      0.86      0.82       224\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_merged_exp_geometric_mean = load_latest_file('merged_exp_geometric_mean.csv')\n",
    "\n",
    "cat_boost_pipe.fit(df_merged_exp_geometric_mean, target_col=top_moa)\n",
    "cat_boost_pipe.evaluate(show_plots=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5530a31",
   "metadata": {},
   "source": [
    "Now we will test our pipeline on geometric mean aggregation with selection of the closest replicate to each mean-based reference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e12fb851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6084567\ttotal: 45.6ms\tremaining: 13.6s\n",
      "50:\tlearn: 0.9790918\ttotal: 1.47s\tremaining: 7.19s\n",
      "100:\tlearn: 0.9961783\ttotal: 2.86s\tremaining: 5.64s\n",
      "150:\tlearn: 0.9995759\ttotal: 4.28s\tremaining: 4.22s\n",
      "200:\tlearn: 1.0000000\ttotal: 5.74s\tremaining: 2.83s\n",
      "250:\tlearn: 1.0000000\ttotal: 7.3s\tremaining: 1.42s\n",
      "299:\tlearn: 1.0000000\ttotal: 8.69s\tremaining: 0us\n",
      "\n",
      "🎯 Accuracy: 0.8839\n",
      "🎯 Macro F1-score: 0.3128\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "   moa_agonist       0.00      0.00      0.00        14\n",
      "moa_antagonist       0.00      0.00      0.00        12\n",
      " moa_inhibitor       0.88      1.00      0.94       198\n",
      "\n",
      "      accuracy                           0.88       224\n",
      "     macro avg       0.29      0.33      0.31       224\n",
      "  weighted avg       0.78      0.88      0.83       224\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/vspaint/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/miniconda3/envs/vspaint/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/miniconda3/envs/vspaint/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "df_merged_exp_closest_geometric_mean = load_latest_file('merged_exp_closest_geometric_mean.csv')\n",
    "\n",
    "cat_boost_pipe.fit(df_merged_exp_closest_geometric_mean, target_col=top_moa)\n",
    "cat_boost_pipe.evaluate(show_plots=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a6faf3",
   "metadata": {},
   "source": [
    "Now we will test our pipeline on arithmetic–geometric mean aggregation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "41e6037e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.5849560\ttotal: 42.5ms\tremaining: 12.7s\n",
      "50:\tlearn: 0.9743312\ttotal: 1.51s\tremaining: 7.37s\n",
      "100:\tlearn: 0.9974533\ttotal: 3.15s\tremaining: 6.2s\n",
      "150:\tlearn: 0.9995759\ttotal: 4.66s\tremaining: 4.59s\n",
      "200:\tlearn: 1.0000000\ttotal: 6.13s\tremaining: 3.02s\n",
      "250:\tlearn: 1.0000000\ttotal: 7.71s\tremaining: 1.5s\n",
      "299:\tlearn: 1.0000000\ttotal: 9.11s\tremaining: 0us\n",
      "\n",
      "🎯 Accuracy: 0.8661\n",
      "🎯 Macro F1-score: 0.3606\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "   moa_agonist       0.00      0.00      0.00        14\n",
      "moa_antagonist       1.00      0.08      0.15        12\n",
      " moa_inhibitor       0.89      0.97      0.93       198\n",
      "\n",
      "      accuracy                           0.87       224\n",
      "     macro avg       0.63      0.35      0.36       224\n",
      "  weighted avg       0.84      0.87      0.83       224\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_merged_exp_agm = load_latest_file('merged_exp_agm.csv')\n",
    "\n",
    "cat_boost_pipe.fit(df_merged_exp_agm, target_col=top_moa)\n",
    "cat_boost_pipe.evaluate(show_plots=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fdc6070",
   "metadata": {},
   "source": [
    "Now we will test our pipeline on arithmetic–geometric mean aggregation with selection of the closest replicate to each mean-based reference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9519bf77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6147883\ttotal: 33.1ms\tremaining: 9.91s\n",
      "50:\tlearn: 0.9821050\ttotal: 1.89s\tremaining: 9.22s\n",
      "100:\tlearn: 0.9974533\ttotal: 3.63s\tremaining: 7.14s\n",
      "150:\tlearn: 0.9991518\ttotal: 5.11s\tremaining: 5.04s\n",
      "200:\tlearn: 1.0000000\ttotal: 6.6s\tremaining: 3.25s\n",
      "250:\tlearn: 1.0000000\ttotal: 8.1s\tremaining: 1.58s\n",
      "299:\tlearn: 1.0000000\ttotal: 9.56s\tremaining: 0us\n",
      "\n",
      "🎯 Accuracy: 0.8839\n",
      "🎯 Macro F1-score: 0.3128\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "   moa_agonist       0.00      0.00      0.00        14\n",
      "moa_antagonist       0.00      0.00      0.00        12\n",
      " moa_inhibitor       0.88      1.00      0.94       198\n",
      "\n",
      "      accuracy                           0.88       224\n",
      "     macro avg       0.29      0.33      0.31       224\n",
      "  weighted avg       0.78      0.88      0.83       224\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/vspaint/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/miniconda3/envs/vspaint/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/miniconda3/envs/vspaint/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "df_merged_exp_closest_agm = load_latest_file('merged_exp_closest_agm.csv')\n",
    "\n",
    "cat_boost_pipe.fit(df_merged_exp_closest_agm, target_col=top_moa)\n",
    "cat_boost_pipe.evaluate(show_plots=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9c293e",
   "metadata": {},
   "source": [
    "## Summary of results\n",
    "\n",
    "As part of this investigation, I evaluated various strategies for aggregating features across multiple cell lines using a **CatBoostClassifier** for MOA (mechanism of action) classification. The objective was to determine which aggregation approach leads to improved predictive performance, especially for underrepresented classes.\n",
    "\n",
    "### Aggregation Methods Compared\n",
    "\n",
    "1. **Mean** (arithmetic mean)\n",
    "2. **Geometric mean**\n",
    "3. **Arithmetic–Geometric Mean (AGM)**\n",
    "4. **Closest compound to geometric mean**\n",
    "5. **Closest compound to arithmetic–geometric mean**\n",
    "\n",
    "### Summary of Results\n",
    "\n",
    "| Aggregation Method              | Accuracy | Macro F1 | Notes |\n",
    "|--------------------------------|----------|----------|-------|\n",
    "| **Mean**                       | 0.8795   | 0.3535   | Decent macro F1; better than geometric mean |\n",
    "| **Geometric Mean**             | 0.8616   | 0.3086   | Weak generalization to minor classes |\n",
    "| **AGM**                        | 0.8661   | 0.3606   | Best macro F1; recall on `antagonist` slightly improved |\n",
    "| **Closest to Geometric Mean** | 0.8839   | 0.3128   | High accuracy; fails to classify minor classes |\n",
    "| **Closest to AGM**            | 0.8839   | 0.3128   | Identical to above; no contribution from `agonist`/`antagonist` |\n",
    "\n",
    "### Method-by-Method Analysis\n",
    "\n",
    "#### Mean\n",
    "- A strong baseline method with **high accuracy** and moderate **macro F1-score (0.3535)**.\n",
    "- Provides reasonable precision and recall for the dominant class (`moa_inhibitor`), but struggles on minority classes.\n",
    "- **Conclusion**: A reliable default aggregation; retains generalizability better than geometric methods.\n",
    "\n",
    "#### Geometric Mean\n",
    "- Performs slightly worse than the arithmetic mean on all metrics.\n",
    "- Fails to produce any predictions for `moa_agonist` or `moa_antagonist`.\n",
    "- **Conclusion**: Too conservative; information may be overly compressed in the log-domain.\n",
    "\n",
    "#### Arithmetic–Geometric Mean (AGM)\n",
    "- Achieves the **highest macro F1-score (0.3606)** among all methods tested.\n",
    "- Notably, it is the only method that yielded **non-zero recall** on `moa_antagonist`.\n",
    "- **Conclusion**: Most promising aggregation method when class balance is important.\n",
    "\n",
    "#### Closest to Geometric Mean\n",
    "- Despite achieving the **highest accuracy (0.8839)**, it completely ignores minority classes.\n",
    "- Precision and recall for both `moa_agonist` and `moa_antagonist` are 0.\n",
    "- **Conclusion**: Overfits to dominant class; not suitable when class diversity matters.\n",
    "\n",
    "#### Closest to AGM\n",
    "- Identical in performance to \"closest geometric mean\", suggesting similar failure modes.\n",
    "- No contribution from rare MOAs despite proximity to a “balanced” synthetic compound.\n",
    "- **Conclusion**: Selecting the closest real compound sacrifices representation richness.\n",
    "\n",
    "### Final Recommendation\n",
    "\n",
    "The **Arithmetic–Geometric Mean (AGM)** stands out as the most effective aggregation strategy in this study. While it does not achieve the absolute highest accuracy, it provides the best balance between sensitivity to minority classes and overall classification performance. This makes AGM the most suitable candidate for future modeling and benchmarking efforts, particularly in settings with class imbalance.\n",
    "\n",
    "### Future directions:\n",
    "- Investigating attention-based or learned aggregation schemes\n",
    "- Using ensemble methods across multiple aggregation strategies\n",
    "- Integrating biological priors (e.g., tissue type, cell origin) to weight contributions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vspaint",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
