{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e98a94fc",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In this notebook, I compare two fundamentally different approaches to molecular representation based on SMILES strings:\n",
    "- Morgan fingerprints (ECFP) â€” hand-engineered binary features based on molecular substructures.\n",
    "- [MolCLR](https://github.com/yuyangw/MolCLR) embeddings â€” learned continuous representations obtained via contrastive graph-based pretraining.\n",
    "\n",
    "The goal is to evaluate how each type of feature impacts MoA classification performance, particularly in detecting rare or underrepresented classes.\n",
    "\n",
    "By training and testing models on identical datasets with only the SMILES representation varied, I aim to assess:\n",
    "- Which representation yields better overall and per-class metrics\n",
    "- Whether learned embeddings provide a tangible advantage over traditional descriptors\n",
    "- How both approaches scale with model complexity and label imbalance\n",
    "\n",
    "This comparison helps inform the design of future multimodal models by selecting the most informative and generalizable molecular descriptors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a477f606",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from datetime import date\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "260ab57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths to data\n",
    "save_path = \"result/\"\n",
    "\n",
    "def load_latest_file(suffix: str):\n",
    "    # loading our final dataset\n",
    "    file_merged_type = '/*[0-9]_' + suffix\n",
    "    files_merged = glob.glob(save_path + file_merged_type)\n",
    "\n",
    "    # gets latest file\n",
    "    max_file_merged = max(files_merged, key=os.path.getctime)\n",
    "\n",
    "    # load file\n",
    "    return pd.read_csv(max_file_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1658bec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged_morgan = load_latest_file('merged_exp_agm.csv')\n",
    "df_merged_molcrl = load_latest_file('merged_molcrl_exp_agm.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "889e563a",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_cols = [col for col in df_merged_morgan.columns if col.startswith('Metadata_')]\n",
    "binary_cols = [col for col in df_merged_morgan.columns if col.startswith('binary_')]\n",
    "chemical_cols = [col for col in df_merged_morgan.columns if col.startswith('chemical_')]\n",
    "moa_cols = [col for col in df_merged_morgan.columns if col.startswith('moa_')]\n",
    "drug_status_cols = [col for col in df_merged_morgan.columns if col.startswith('drug_status_')]\n",
    "fingerprints_cols = [col for col in df_merged_morgan.columns if col.startswith('fp_')]\n",
    "morphology_cols = [col for col in df_merged_morgan.columns if col.startswith('morphology_')]\n",
    "\n",
    "moa_counts = df_merged_morgan[moa_cols].sum().sort_values(ascending=False)\n",
    "top_moa = moa_counts[moa_counts > 100].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0918c249",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score, roc_curve, auc, roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "class MultimodalMoAPipeline:\n",
    "    \"\"\"\n",
    "    A pipeline for multimodal classification tasks using morphological, chemical,\n",
    "    and fingerprint features.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    morph_cols : list of str, default=[]\n",
    "        List of column names representing morphological features.\n",
    "\n",
    "    chem_cols : list of str, default=[]\n",
    "        List of column names representing chemical descriptors.\n",
    "\n",
    "    fp_cols : list of str, default=[]\n",
    "        List of column names representing fingerprint features.\n",
    "\n",
    "    use_morph : bool, default=True\n",
    "        Whether to include morphological features in the model.\n",
    "\n",
    "    use_chem : bool, default=True\n",
    "        Whether to include chemical features in the model.\n",
    "\n",
    "    use_fp : bool, default=True\n",
    "        Whether to include fingerprint features in the model.\n",
    "\n",
    "    scaler : str or None, default='standard'\n",
    "        Type of scaler to apply to features. Options:\n",
    "            - 'standard': StandardScaler from sklearn\n",
    "            - None or any other value: no scaling will be applied\n",
    "\n",
    "        Note: Some models like CatBoost do not require scaling.\n",
    "\n",
    "    model : sklearn-like classifier, default=None\n",
    "        A scikit-learn compatible classifier. If None, defaults to\n",
    "        RandomForestClassifier with predefined parameters.\n",
    "\n",
    "    random_state : int, default=42\n",
    "        Random seed for reproducibility.\n",
    "\n",
    "    use_gridsearch : bool, default=False\n",
    "        Whether to perform GridSearchCV to tune hyperparameters.\n",
    "        Only supported for sklearn-compatible estimators.\n",
    "    \"\"\"\n",
    "    def __init__(self, morph_cols=[], chem_cols=[], fp_cols=[],\n",
    "                 use_morph=True, use_chem=True, use_fp=True,\n",
    "                 scaler='standard', model=None, random_state=42,\n",
    "                 use_gridsearch=False):\n",
    "        self.morph_cols = morph_cols\n",
    "        self.chem_cols = chem_cols\n",
    "        self.fp_cols = fp_cols\n",
    "        self.use_morph = use_morph\n",
    "        self.use_chem = use_chem\n",
    "        self.use_fp = use_fp\n",
    "        \n",
    "        self.scaler_type = scaler\n",
    "        self.random_state = random_state\n",
    "        self.use_gridsearch = use_gridsearch\n",
    "        \n",
    "        self.model = model if model is not None else RandomForestClassifier(n_estimators=200, random_state=random_state, class_weight='balanced', min_samples_leaf=3)\n",
    "\n",
    "    def _get_feature_set(self, df):\n",
    "        cols = []\n",
    "        if self.use_morph:\n",
    "            cols += self.morph_cols\n",
    "        if self.use_chem:\n",
    "            cols += self.chem_cols\n",
    "        if self.use_fp:\n",
    "            cols += self.fp_cols\n",
    "        return df[cols].copy()\n",
    "\n",
    "    def _scale(self, X):\n",
    "        if self.scaler_type == 'standard':\n",
    "            self.scaler = StandardScaler()\n",
    "            X_scaled = pd.DataFrame(self.scaler.fit_transform(X), columns=X.columns, index=X.index)\n",
    "            return X_scaled\n",
    "        return X  # no scaling\n",
    "\n",
    "    def fit(self, df, target_col):\n",
    "        X = self._get_feature_set(df)\n",
    "        X = self._scale(X)\n",
    "\n",
    "        # Support for multilabel: if target_col â€” it's a one-hot list\n",
    "        if isinstance(target_col, list):\n",
    "            df = df.copy()\n",
    "            df['__moa_label'] = df[target_col].idxmax(axis=1)\n",
    "            y = df['__moa_label']\n",
    "        else:\n",
    "            y = df[target_col]\n",
    "\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(\n",
    "            X, y, stratify=y, test_size=0.2, random_state=self.random_state\n",
    "        )\n",
    "\n",
    "        if self.use_gridsearch:\n",
    "            param_grid = {\n",
    "                'n_estimators': [100, 200],\n",
    "                'max_depth': [None, 10, 20],\n",
    "                'min_samples_leaf': [1, 3, 5],\n",
    "                'class_weight': ['balanced']\n",
    "            }\n",
    "            base_model = RandomForestClassifier(random_state=self.random_state)\n",
    "            cv_strategy = StratifiedKFold(n_splits=3, shuffle=True, random_state=self.random_state)\n",
    "            grid = GridSearchCV(base_model, param_grid, scoring='f1_macro', cv=cv_strategy, n_jobs=-1)\n",
    "            grid.fit(self.X_train, self.y_train)\n",
    "            print(\"Best params from GridSearchCV:\", grid.best_params_)\n",
    "            self.model = grid.best_estimator_\n",
    "        else:\n",
    "            self.model.fit(self.X_train, self.y_train)\n",
    "\n",
    "        self.y_pred = self.model.predict(self.X_test)\n",
    "\n",
    "\n",
    "    def evaluate(self, show_plots=True):\n",
    "        acc = accuracy_score(self.y_test, self.y_pred)\n",
    "        f1 = f1_score(self.y_test, self.y_pred, average='macro')\n",
    "\n",
    "        print(f\"\\nðŸŽ¯ Accuracy: {acc:.4f}\")\n",
    "        print(f\"ðŸŽ¯ Macro F1-score: {f1:.4f}\\n\")\n",
    "        print(\"Classification Report:\\n\")\n",
    "        print(classification_report(self.y_test, self.y_pred))\n",
    "        \n",
    "        if not show_plots:\n",
    "            return\n",
    "\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        cm = confusion_matrix(self.y_test, self.y_pred, labels=self.model.classes_)\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                    xticklabels=self.model.classes_, yticklabels=self.model.classes_)\n",
    "        plt.title(\"Confusion Matrix\")\n",
    "        plt.xlabel(\"Predicted\")\n",
    "        plt.ylabel(\"True\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # PR and ROC curves only for binary classification\n",
    "        if len(self.model.classes_) == 2:\n",
    "            y_proba = self.model.predict_proba(self.X_test)[:, 1]\n",
    "\n",
    "            # Precision-Recall Curve\n",
    "            precision, recall, thresholds = precision_recall_curve(self.y_test, y_proba)\n",
    "            avg_precision = average_precision_score(self.y_test, y_proba)\n",
    "\n",
    "            plt.figure(figsize=(8, 6))\n",
    "            plt.plot(recall, precision, marker='.')\n",
    "            plt.xlabel('Recall')\n",
    "            plt.ylabel('Precision')\n",
    "            plt.title(f'Precision-Recall Curve (AP = {avg_precision:.4f})')\n",
    "            plt.grid()\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "            # ROC Curve\n",
    "            fpr, tpr, _ = roc_curve(self.y_test, y_proba)\n",
    "            roc_auc = roc_auc_score(self.y_test, y_proba)\n",
    "\n",
    "            plt.figure(figsize=(8, 6))\n",
    "            plt.plot(fpr, tpr, label=f'ROC curve (AUC = {roc_auc:.4f})')\n",
    "            plt.plot([0, 1], [0, 1], linestyle='--', color='gray')\n",
    "            plt.xlabel('False Positive Rate')\n",
    "            plt.ylabel('True Positive Rate')\n",
    "            plt.title('ROC Curve')\n",
    "            plt.legend(loc='lower right')\n",
    "            plt.grid()\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "    def plot_importance(self, top_n=30):\n",
    "        if not hasattr(self.model, 'feature_importances_'):\n",
    "            print(\"This model does not support feature importances.\")\n",
    "            return\n",
    "\n",
    "        feat_imp = pd.DataFrame({\n",
    "            'feature': self.X_train.columns,\n",
    "            'importance': self.model.feature_importances_\n",
    "        })\n",
    "\n",
    "        # Figure out the feature groups\n",
    "        def get_group(feature):\n",
    "            if feature in self.morph_cols:\n",
    "                return 'morphology'\n",
    "            elif feature in self.chem_cols:\n",
    "                return 'chemistry'\n",
    "            elif feature in self.fp_cols:\n",
    "                return 'fingerprint'\n",
    "            else:\n",
    "                return 'other'\n",
    "\n",
    "        feat_imp['group'] = feat_imp['feature'].apply(get_group)\n",
    "\n",
    "        # Group by feature group and sum importances\n",
    "        grouped = feat_imp.groupby('group')['importance'].sum().sort_values(ascending=False)\n",
    "        print(\"\\nðŸ“Š Feature Importance by Group:\")\n",
    "        print(grouped)\n",
    "\n",
    "        # Sort and select top_n features\n",
    "        feat_imp = feat_imp.sort_values(by='importance', ascending=False).head(top_n)\n",
    "\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        sns.barplot(data=feat_imp, x='importance', y='feature', hue='group', dodge=False, palette='viridis')\n",
    "        plt.title(f\"Top {top_n} Feature Importances by Group\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        return feat_imp\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bafa9104",
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "X = df_merged_morgan[morphology_cols + chemical_cols + fingerprints_cols]\n",
    "y = df_merged_morgan[top_moa].idxmax(axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
    "\n",
    "classes = y_train.unique()\n",
    "weights = compute_class_weight(class_weight='balanced', classes=classes, y=y_train)\n",
    "class_weights = dict(zip(classes, weights))\n",
    "\n",
    "cat_boost_model = CatBoostClassifier(\n",
    "    iterations=300,\n",
    "    depth=6,\n",
    "    learning_rate=0.1,\n",
    "    loss_function='MultiClass',\n",
    "    class_weights=class_weights,\n",
    "    eval_metric='TotalF1',\n",
    "    random_seed=42,\n",
    "    verbose=50,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ebaffea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_boost_pipe = MultimodalMoAPipeline(\n",
    "    morph_cols=morphology_cols,\n",
    "    chem_cols=chemical_cols,\n",
    "    fp_cols=fingerprints_cols,\n",
    "    use_gridsearch=False,\n",
    "    model=cat_boost_model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7353736a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.5849560\ttotal: 120ms\tremaining: 35.9s\n",
      "50:\tlearn: 0.9743312\ttotal: 1.8s\tremaining: 8.78s\n",
      "100:\tlearn: 0.9974533\ttotal: 3.41s\tremaining: 6.71s\n",
      "150:\tlearn: 0.9995759\ttotal: 4.9s\tremaining: 4.83s\n",
      "200:\tlearn: 1.0000000\ttotal: 6.66s\tremaining: 3.28s\n",
      "250:\tlearn: 1.0000000\ttotal: 8.33s\tremaining: 1.63s\n",
      "299:\tlearn: 1.0000000\ttotal: 9.9s\tremaining: 0us\n",
      "\n",
      "ðŸŽ¯ Accuracy: 0.8661\n",
      "ðŸŽ¯ Macro F1-score: 0.3606\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "   moa_agonist       0.00      0.00      0.00        14\n",
      "moa_antagonist       1.00      0.08      0.15        12\n",
      " moa_inhibitor       0.89      0.97      0.93       198\n",
      "\n",
      "      accuracy                           0.87       224\n",
      "     macro avg       0.63      0.35      0.36       224\n",
      "  weighted avg       0.84      0.87      0.83       224\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cat_boost_pipe.fit(df_merged_morgan, target_col=top_moa)\n",
    "cat_boost_pipe.evaluate(show_plots=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89d18e1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.5641783\ttotal: 120ms\tremaining: 36s\n",
      "50:\tlearn: 0.9682054\ttotal: 2.06s\tremaining: 10.1s\n",
      "100:\tlearn: 0.9949034\ttotal: 3.89s\tremaining: 7.67s\n",
      "150:\tlearn: 0.9995759\ttotal: 5.59s\tremaining: 5.52s\n",
      "200:\tlearn: 1.0000000\ttotal: 7.45s\tremaining: 3.67s\n",
      "250:\tlearn: 1.0000000\ttotal: 9.23s\tremaining: 1.8s\n",
      "299:\tlearn: 1.0000000\ttotal: 10.9s\tremaining: 0us\n",
      "\n",
      "ðŸŽ¯ Accuracy: 0.8705\n",
      "ðŸŽ¯ Macro F1-score: 0.3927\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "   moa_agonist       0.20      0.07      0.11        14\n",
      "moa_antagonist       0.50      0.08      0.14        12\n",
      " moa_inhibitor       0.89      0.97      0.93       198\n",
      "\n",
      "      accuracy                           0.87       224\n",
      "     macro avg       0.53      0.38      0.39       224\n",
      "  weighted avg       0.83      0.87      0.84       224\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cat_boost_pipe.fit(df_merged_molcrl, target_col=top_moa)\n",
    "cat_boost_pipe.evaluate(show_plots=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7c5c93",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this section of the study, I compared two distinct approaches for extracting molecular features from SMILES strings:\n",
    "\n",
    "- **Morgan fingerprints**: traditional circular substructure fingerprints.\n",
    "- **MolCLR embeddings**: learned representations using contrastive learning on molecular graphs.\n",
    "\n",
    "Both representations were evaluated using the same CatBoostClassifier and identical data preprocessing pipelines. The goal was to assess whether modern embedding techniques like MolCLR provide tangible improvements over established fingerprint methods in MOA classification tasks.\n",
    "\n",
    "### Summary of Results\n",
    "\n",
    "| SMILES Representation | Accuracy | Macro F1 | Notes |\n",
    "|------------------------|----------|----------|-------|\n",
    "| **Morgan fingerprints** | 0.8661   | 0.3606   | Higher precision on `moa_antagonist`, but zero recall on `moa_agonist` |\n",
    "| **MolCLR embeddings**   | 0.8705   | 0.3927   | Slightly better macro F1; improved balance across minor classes |\n",
    "\n",
    "### Analysis\n",
    "\n",
    "#### Morgan Fingerprints\n",
    "- Delivered strong overall accuracy (0.8661) and good classification of the dominant class (`moa_inhibitor`).\n",
    "- Achieved perfect precision (1.00) but very low recall (0.08) on `moa_antagonist`.\n",
    "- Failed to produce any predictions for `moa_agonist`.\n",
    "- **Conclusion**: While reliable for dominant patterns, this approach underperforms in generalization to rare classes.\n",
    "\n",
    "#### MolCLR Embeddings\n",
    "- Slightly improved overall accuracy and notably better macro F1-score (0.3927).\n",
    "- Successfully identified samples from all three classes, albeit with low recall.\n",
    "- Demonstrated more balanced error distribution, reflecting better minor-class sensitivity.\n",
    "- **Conclusion**: A more generalizable and balanced representation; particularly promising for underrepresented MOAs.\n",
    "\n",
    "### Final Recommendation\n",
    "\n",
    "**MolCLR embeddings** outperform Morgan fingerprints in terms of class balance and generalization, despite both approaches showing similar overall accuracy. The higher macro F1-score achieved by MolCLR indicates its superior ability to model diverse MOA classes. Given the importance of detecting rare mechanisms in practical drug discovery tasks, I recommend **adopting MolCLR embeddings** for future iterations of this pipeline.\n",
    "\n",
    "### Future directions:\n",
    "- Fine-tuning the MolCLR encoder on domain-specific MOA data\n",
    "- Exploring hybrid approaches that combine fingerprints and embeddings\n",
    "- Incorporating domain knowledge into representation learning objectives"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vspaint",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
